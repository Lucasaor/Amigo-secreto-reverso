from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage
from dotenv import load_dotenv
import os

load_dotenv()

class GeradorPerguntas:
    def __init__(self):
        api_key = os.getenv("OPENAI_API_KEY")
        self.llm = ChatOpenAI(api_key=api_key)
        self.historico_perguntas = []

    def gerar_pergunta(self) -> str:
        with open("prompts/template.txt", "r") as f:
            contexto = f.read()
        
        # Adiciona o hist贸rico de perguntas ao contexto
        contexto_completo = contexto + "\nHist贸rico de perguntas:\n" + "\n".join(self.historico_perguntas)
        
        mensagens = [
            SystemMessage(
            content=contexto_completo),
            HumanMessage(
            content="Gere a pr贸xima pergunta"
            )
        ]
        resposta = self.llm.invoke(mensagens)
        
        # Armazena a pergunta gerada no hist贸rico
        self.historico_perguntas.append(resposta.content)
        
        return resposta.content


